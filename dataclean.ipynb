{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ebc3a3",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from string import punctuation\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk import sent_tokenize,word_tokenize,wordpunct_tokenize\n",
    "\n",
    "corpus=\"Artificial Intelligence (AI) is transforming industries! From healthcare to finance, AI is helping automate processes, improve decision-making, and create innovative products. But, it also raises ethical concernsâ€”such as job displacement and data privacy.\"\n",
    "\n",
    "sent=sent_tokenize(corpus)\n",
    "words=word_tokenize(corpus)\n",
    "wordswithoutpun=wordpunct_tokenize(corpus)\n",
    "\n",
    "print(\"Sentences: \")\n",
    "for i in sent:\n",
    "    print(i)\n",
    "\n",
    "print(\"Words:\")\n",
    "for i in words:\n",
    "    print(i)\n",
    "\n",
    "total=0\n",
    "for i in wordswithoutpun:\n",
    "    if i not in punctuation:\n",
    "        total+=1\n",
    "\n",
    "print(f\"Total num of words is {total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042fe579",
   "metadata": {},
   "source": [
    "## Stemming + Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d43b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word ----> porter ----> regex ----> snowball\n",
      "children ----> children ----> children ----> children\n",
      "were ----> were ----> wer ----> were\n",
      "happily ----> happili ----> happily ----> happili\n",
      "playing ----> play ----> play ----> play\n",
      "playgrounds ----> playground ----> playground ----> playground\n",
      "while ----> while ----> whil ----> while\n",
      "wolves ----> wolv ----> wolve ----> wolv\n",
      "were ----> were ----> wer ----> were\n",
      "hunting ----> hunt ----> hunt ----> hunt\n",
      "nearby ----> nearbi ----> nearby ----> nearbi\n",
      "Studies ----> studi ----> Studie ----> studi\n",
      "about ----> about ----> about ----> about\n",
      "modernization ----> modern ----> modernization ----> modern\n",
      "globalizations ----> global ----> globalization ----> global\n",
      "digitalizations ----> digit ----> digitalization ----> digit\n",
      "rapidly ----> rapidli ----> rapidly ----> rapid\n",
      "increasing ----> increas ----> increas ----> increas\n",
      "However ----> howev ----> However ----> howev\n",
      "some ----> some ----> som ----> some\n",
      "organizations ----> organ ----> organization ----> organ\n",
      "disabling ----> disabl ----> disabl ----> disabl\n",
      "unnecessary ----> unnecessari ----> unnecessary ----> unnecessari\n",
      "features ----> featur ----> feature ----> featur\n",
      "simplify ----> simplifi ----> simplify ----> simplifi\n",
      "their ----> their ----> their ----> their\n",
      "systems ----> system ----> system ----> system\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer,RegexpStemmer,SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "text=\"\"\"The children were happily playing in the playgrounds while the wolves were hunting nearby.  \n",
    "Studies about modernization, globalizations, and digitalizations are rapidly increasing.  \n",
    "However, some organizations are disabling unnecessary features to simplify their systems.\"\"\"\n",
    "\n",
    "tokens=word_tokenize(text)\n",
    "\n",
    "\n",
    "porter=PorterStemmer()\n",
    "regex=RegexpStemmer('ing$|s$|e$|able$', min=3)\n",
    "snowball=SnowballStemmer('english')\n",
    "lst=[]\n",
    "print(\"word ----> porter ----> regex ----> snowball\")\n",
    "for i in tokens:\n",
    "    if i not in punctuation and len(i)>=4:\n",
    "        print(f\"{i} ----> {porter.stem(i)} ----> {regex.stem(i)} ----> {snowball.stem(i)}\")\n",
    "        lst.append([porter.stem(i),regex.stem(i),snowball.stem(i)])\n",
    "\n",
    "for i in lst:\n",
    "    if i[0]!=i[1] or i[0]!=i[2] or i[1]!=i[2]:\n",
    "        print(f\"{i} ----> {porter.stem(i)} ----> {regex.stem(i)} ----> {snowball.stem(i)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3949a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480afadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a7a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
